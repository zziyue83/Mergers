{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "liked-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import time\n",
    "import pyblp\n",
    "import auxiliary as aux\n",
    "import sqldf\n",
    "import pysqldf as ps\n",
    "from pandasql import sqldf\n",
    "import pandasql\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from clean_data import clean_data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def parse_info(code):\n",
    "    file = open('../../../../All/m_' + code + '/info.txt', mode = 'r')\n",
    "    info_file = file.read()\n",
    "    file.close()\n",
    "\n",
    "    all_info_elements = re.finditer('\\[(.*?):(.*?)\\]', info_file, re.DOTALL)\n",
    "    info_dict = {}\n",
    "    for info in all_info_elements:\n",
    "        info_name = info.group(1).strip()\n",
    "        info_content = info.group(2).strip()\n",
    "        info_dict[info_name] = info_content\n",
    "    return info_dict\n",
    "\n",
    "def adjust_inflation(df, all_vars, month_or_quarter, rename_var = True):\n",
    "\n",
    "    # Import CPIU dataset\n",
    "    cpiu = pd.read_excel('../../../../All/master/cpiu_2000_2020.xlsx', header = 11)\n",
    "    cpiu = cpiu.set_index('Year')\n",
    "    month_dictionary = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "    cpiu = cpiu.rename(columns = month_dictionary)\n",
    "    cpiu = cpiu.drop(['HALF1','HALF2'], axis=1)\n",
    "    cpiu = cpiu.stack()\n",
    "\n",
    "    # Aggregate to the quarter level, if necessary\n",
    "    cpiu = cpiu.reset_index().rename(columns = {'level_1':'month',0:'cpiu'})\n",
    "    if month_or_quarter == 'quarter':\n",
    "        cpiu['quarter'] = cpiu['month'].apply(lambda x: 1 if x <=3 else 2 if ((x>3) & (x<=6)) else 3 if ((x>6) & (x<=9)) else 4)\n",
    "        cpiu = cpiu.groupby(['Year', month_or_quarter]).agg({'cpiu': 'mean'}).reset_index()\n",
    "    if month_or_quarter == 'month':\n",
    "        cpiu = cpiu.set_index(['Year', month_or_quarter]).reset_index()\n",
    "\n",
    "    # Set index value in base period\n",
    "    cpiu['cpiu_201001'] = float(cpiu.loc[(cpiu['Year'] == 2010) & (cpiu[month_or_quarter]==1),'cpiu'])\n",
    "    cpiu = cpiu.rename(columns={'Year': 'year'})\n",
    "    cpiu = cpiu.set_index(['year', month_or_quarter])\n",
    "\n",
    "    # Merge CPIU onto dataframe and adjust prices\n",
    "    df = df.join(cpiu, on=['year', month_or_quarter], how = 'left')\n",
    "    for var in all_vars:\n",
    "        if rename_var:\n",
    "            df[var] = df[var] * (df['cpiu_201001'] / df['cpiu'])\n",
    "        else:\n",
    "            df[var + '_adj'] = df[var] * df['cpiu_201001'] / df['cpiu']\n",
    "    df = df.drop(['cpiu_201001', 'cpiu'], axis = 1)\n",
    "    return df\n",
    "\n",
    "def get_date_range(initial_year_string, final_year_string, pre_months = 24, post_months = 24):\n",
    "        initial_dt = datetime.strptime(initial_year_string, '%Y-%m-%d')\n",
    "        final_dt = datetime.strptime(final_year_string, '%Y-%m-%d')\n",
    "        initial_month_int = initial_dt.year * 12 + initial_dt.month\n",
    "        final_month_int = final_dt.year * 12 + final_dt.month\n",
    "        min_year, min_month = int_to_month(initial_month_int - pre_months)\n",
    "        max_year, max_month = int_to_month(final_month_int + post_months)\n",
    "\n",
    "        string_init = str(int(min_year)) + \"-\" + str(int(min_month))\n",
    "        string_final = str(int(max_year)) + \"-\" + str(int(max_month))\n",
    "        years_range = pd.date_range(string_init, string_final, freq='MS').strftime(\"%Y\").tolist()\n",
    "        months_range = pd.date_range(string_init, string_final, freq='MS').strftime(\"%m\").tolist()\n",
    "\n",
    "        date_range = pd.DataFrame(zip(years_range, months_range))\n",
    "\n",
    "        return date_range\n",
    "    \n",
    "def load_store_table(year):\n",
    "    store_path = \"../../../../Data/nielsen_extracts/RMS/\" + year + \"/Annual_Files/stores_\" + year + \".tsv\"\n",
    "    store_table = pd.read_csv(store_path, delimiter = \"\\t\", index_col = \"store_code_uc\")\n",
    "    print(\"Loaded store file of \"+ year)\n",
    "    return store_table\n",
    "\n",
    "def get_product_map(groups):\n",
    "    products_path = \"../../../../Data/nielsen_extracts/RMS/Master_Files/Latest/products.tsv\"\n",
    "    products = pd.read_csv(products_path, delimiter = \"\\t\", encoding = \"cp1252\", header = 0, index_col = [\"upc\",\"upc_ver_uc\"])\n",
    "    int_groups = [int(i) for i in groups]\n",
    "    wanted_products = products[products['product_group_code'].isin(int_groups)]\n",
    "    product_map = wanted_products\n",
    "    return product_map\n",
    "\n",
    "def get_upc_ver_uc_map(year):\n",
    "    upc_ver_path = \"../../../../Data/nielsen_extracts/RMS/\"+str(year)+\"/Annual_Files/rms_versions_\"+str(year)+\".tsv\"\n",
    "    upc_vers = pd.read_csv(upc_ver_path, delimiter = \"\\t\", encoding = \"cp1252\", header = 0, index_col = \"upc\")\n",
    "    upc_vers = upc_vers['upc_ver_uc']\n",
    "    upc_ver_map = upc_vers.to_dict()\n",
    "    return upc_ver_map\n",
    "\n",
    "def get_conversion_map(code, final_unit, method = 'mode'):\n",
    "    # Get in the conversion map -- size1_units, multiplication\n",
    "    master_conversion = pd.read_csv('../../../../All/master/unit_conversion.csv')\n",
    "    assert master_conversion['final_unit'].str.contains(final_unit).any(), \"Cannot find %r as a final_unit\" % final_unit\n",
    "    master_conversion = master_conversion[master_conversion['final_unit'] == final_unit]\n",
    "\n",
    "    these_units = pd.read_csv('../../../../All/m_' + code + '/properties/units_edited.csv')\n",
    "    these_units['conversion'] = 0\n",
    "\n",
    "    # Anything that has convert = 1 must be in the master folder\n",
    "    convertible = these_units.loc[these_units.convert == 1].copy()\n",
    "    for this_unit in convertible.units.unique():\n",
    "        assert master_conversion['initial_unit'].str.contains(this_unit).any(), \"Cannot find %r as an initial_unit\" % this_unit\n",
    "        if this_unit in master_conversion.initial_unit.unique():\n",
    "            convert_factor = master_conversion.conversion[master_conversion.initial_unit == this_unit].values\n",
    "            these_units.loc[these_units.units == this_unit, 'conversion'] = convert_factor\n",
    "            convertible.loc[convertible.units == this_unit, 'conversion'] = convert_factor\n",
    "\n",
    "    # Convert the total quantity\n",
    "    convertible['total_quantity'] = convertible['total_quantity'] * convertible['conversion']\n",
    "\n",
    "    # The \"method\" for convert = 0 is mapped to the \"method\" for the convert = 1\n",
    "    # with the largest quantity\n",
    "    where_largest = convertible.total_quantity.idxmax()\n",
    "    if method == 'mode':\n",
    "        base_size = convertible.loc[where_largest]['mode']\n",
    "        other_size = these_units[these_units.convert == 0]['mode']\n",
    "    else:\n",
    "        base_size = convertible.loc[where_largest]['median']\n",
    "        other_size = these_units[these_units.convert == 0]['median']\n",
    "\n",
    "    these_units.conversion[these_units.convert == 0] = convertible.conversion[where_largest] * base_size / other_size\n",
    "    these_units = these_units[['units', 'conversion']]\n",
    "    these_units = these_units.rename(columns = {'units' : 'size1_units'})\n",
    "    these_units = these_units.set_index('size1_units')\n",
    "\n",
    "    conversion_map = these_units.to_dict()\n",
    "    return conversion_map\n",
    "def load_chunked_year_module_movement_table(year, group, module, path = ''):\n",
    "    if path == '':\n",
    "        path = \"../../../../Data/nielsen_extracts/RMS/\" + year + \"/Movement_Files/\" + group + \"_\" + year + \"/\" + module + \"_\" + year + \".tsv\"\n",
    "    assert os.path.exists(path), \"File does not exist: %r\" % path\n",
    "    table = pd.read_csv(path, delimiter = \"\\t\", chunksize = 10000000)\n",
    "    return table\n",
    "\n",
    "def aggregate_movement(code, years, groups, modules, month_or_quarter, conversion_map, merger_start_date, merger_stop_date, market_size_scale = 1.5, pre_months = 24, post_months = 24):\n",
    "\n",
    "    # Get the relevant range\n",
    "    stop_dt = datetime.strptime(merger_stop_date, '%Y-%m-%d')\n",
    "    start_dt = datetime.strptime(merger_start_date, '%Y-%m-%d')\n",
    "    stop_month_int = stop_dt.year * 12 + stop_dt.month\n",
    "    start_month_int = start_dt.year * 12 + start_dt.month\n",
    "\n",
    "    min_year, min_month = aux.int_to_month(start_month_int - pre_months)\n",
    "    max_year, max_month = aux.int_to_month(stop_month_int + post_months)\n",
    "    min_quarter = np.ceil(min_month/3)\n",
    "    max_quarter = np.ceil(max_month/3)\n",
    "\n",
    "    #manual fix for baby strained food\n",
    "    if ((code=='1817013020_3') & (max_year > 2008)):\n",
    "        max_year = 2008\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2008, years))\n",
    "\n",
    "    #manual fix for bread\n",
    "    if ((code=='2203820020_1') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for buns\n",
    "    if ((code=='2203820020_2') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for rolls\n",
    "    if ((code=='2203820020_3') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for pies\n",
    "    if ((code=='2203820020_8') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for bakery remaining\n",
    "    if ((code=='2203820020_10') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for cheesecake\n",
    "    if ((code=='2203820020_11') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for biscuits\n",
    "    if ((code=='2203820020_12') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "        #manual fix for RBC_Bread\n",
    "    if ((code=='2033113020_2') & (min_year < 2007)):\n",
    "        min_year = 2007\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2007, years))\n",
    "\n",
    "        #manual fix for RBC_Cake\n",
    "    if ((code=='2033113020_3') & (min_year < 2007)):\n",
    "        min_year = 2007\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2007, years))\n",
    "\n",
    "        #manual fix for Headache pills\n",
    "    if ((code=='2373087020_1') & (min_year < 2010)):\n",
    "        min_year = 2010\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2010, years))\n",
    "\n",
    "        #manual fix for School and Office Supplies\n",
    "    if ((code=='2363232020_4') & (min_year < 2010)):\n",
    "        min_year = 2010\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2010, years))\n",
    "\n",
    "    area_time_upc_list = []\n",
    "    product_map = get_product_map(list(set(groups)))\n",
    "    add_from_map = ['brand_code_uc', 'brand_descr', 'multi', 'size1_units', 'size1_amount']\n",
    "    aggregation_function = {'week_end' : 'first', 'units' : 'sum', 'prmult' : 'mean', 'price' : 'mean', 'feature' : 'first', 'display' : 'first', 'store_code_uc' : 'first', 'sales' : 'sum', 'module' : 'first'}\n",
    "\n",
    "    #for year in years:\n",
    "    store_table = load_store_table(year)\n",
    "    store_map = store_table.to_dict()\n",
    "    dma_map = store_map['dma_code']\n",
    "    upc_ver_map = get_upc_ver_uc_map(year)\n",
    "\n",
    "    for group, module in zip(groups, modules):\n",
    "        movement_table = load_chunked_year_module_movement_table(year, group, module)\n",
    "\n",
    "        for data_chunk in tqdm(movement_table):\n",
    "            data_chunk['year'] = np.floor(data_chunk['week_end']/10000)\n",
    "            data_chunk['year'] = data_chunk['year'].astype(int)\n",
    "            if month_or_quarter == \"month\":\n",
    "                data_chunk[month_or_quarter] = np.floor((data_chunk['week_end'] % 10000)/100)\n",
    "                data_chunk[month_or_quarter] = data_chunk[month_or_quarter].astype(int)\n",
    "\n",
    "                if int(year) == min_year:\n",
    "                    data_chunk = data_chunk[data_chunk.month >= min_month]\n",
    "                elif int(year) == max_year:\n",
    "                    data_chunk = data_chunk[data_chunk.month <= max_month]\n",
    "            elif month_or_quarter == \"quarter\":\n",
    "                data_chunk[month_or_quarter] = np.ceil(np.floor((data_chunk['week_end'] % 10000)/100)/3)\n",
    "                data_chunk[month_or_quarter] = data_chunk[month_or_quarter].astype(int)\n",
    "                if int(year) == min_year:\n",
    "                    data_chunk = data_chunk[data_chunk.quarter >= min_quarter]\n",
    "                elif int(year) == max_year:\n",
    "                    data_chunk = data_chunk[data_chunk.quarter <= max_quarter]\n",
    "\n",
    "            data_chunk['dma_code'] = data_chunk['store_code_uc'].map(dma_map)\n",
    "            data_chunk['sales'] = data_chunk['price'] * data_chunk['units'] / data_chunk['prmult']\n",
    "            data_chunk['module'] = int(module)\n",
    "            data_chunk['upc_ver_uc'] = data_chunk['upc'].map(upc_ver_map)\n",
    "            area_time_upc = data_chunk.groupby(['year', month_or_quarter, 'upc', 'upc_ver_uc', 'dma_code'], as_index = False).aggregate(aggregation_function).reindex(columns = data_chunk.columns)\n",
    "            area_time_upc_list.append(area_time_upc)\n",
    "\n",
    "    area_time_upc = pd.concat(area_time_upc_list)\n",
    "    area_time_upc = area_time_upc.groupby(['year', month_or_quarter, 'upc', 'upc_ver_uc', 'dma_code'], as_index = False).aggregate(aggregation_function).reindex(columns = area_time_upc.columns)\n",
    "    area_time_upc = area_time_upc.join(product_map[add_from_map], on=['upc','upc_ver_uc'], how='left')\n",
    "    area_time_upc = clean_data(code, area_time_upc)\n",
    "    area_time_upc['conversion'] = area_time_upc['size1_units'].map(conversion_map['conversion'])\n",
    "    area_time_upc['volume'] = area_time_upc['units'] * area_time_upc['size1_amount'] * area_time_upc['multi'] * area_time_upc['conversion']\n",
    "    area_time_upc['prices'] = area_time_upc['sales'] / area_time_upc['volume']\n",
    "    \n",
    "    area_time_upc.drop(['week_end'], axis=1, inplace=True)\n",
    "\n",
    "    # Normalize the prices by the CPI.  Let January 2010 = 1.\n",
    "    area_time_upc = adjust_inflation(area_time_upc, ['prices', 'sales'], month_or_quarter)\n",
    "\n",
    "    # Get the market sizes here, by summing volume within dma-time and then taking 1.5 times max within-dma\n",
    "    short_area_time_upc = area_time_upc[['dma_code', 'year', month_or_quarter, 'volume', 'sales']]\n",
    "    market_sizes = short_area_time_upc.groupby(['dma_code', 'year', month_or_quarter]).sum()\n",
    "    market_sizes['market_size'] = market_size_scale * market_sizes['volume'].groupby('dma_code').transform('max')\n",
    "    market_sizes = market_sizes.rename(columns = {'sales': 'total_sales', 'volume' : 'total_volume'})\n",
    "\n",
    "    # Save the output if this is month\n",
    "    if month_or_quarter == 'month':\n",
    "        market_sizes.to_csv('../../../../All/m_' + code + '/intermediate/market_sizes.csv', sep = ',', encoding = 'utf-8')\n",
    "\n",
    "    # Shares = volume / market size.  Map market sizes back and get shares.\n",
    "    area_time_upc = area_time_upc.join(market_sizes.drop('total_volume', axis=1), on = ['dma_code', 'year', month_or_quarter])\n",
    "    area_time_upc['shares'] = area_time_upc['volume'] / area_time_upc['market_size']\n",
    "\n",
    "    return area_time_upc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "automotive-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded store file of 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['store_code_uc', 'upc', 'units', 'prmult', 'price', 'feature',\n",
       "       'display', 'year', 'month', 'dma_code', 'sales', 'module', 'upc_ver_uc',\n",
       "       'brand_code_uc', 'brand_descr', 'multi', 'size1_units', 'size1_amount',\n",
       "       'conversion', 'volume', 'prices', 'total_sales', 'market_size',\n",
       "       'shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### objective of this is to get area_month_upc BECAUSE THIS HAS STORE UC CODES!\n",
    "\n",
    "#setup\n",
    "code = '2641303020_8'\n",
    "info_dict = parse_info(code)\n",
    "info_dict.keys()\n",
    "final_unit = info_dict['FinalUnits']\n",
    "\n",
    "groups, modules = aux.get_groups_and_modules(info_dict[\"MarketDefinition\"])\n",
    "# FIXUP for 1 year\n",
    "#years = aux.get_years(info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "years = 2012\n",
    "year = '2012'\n",
    "\n",
    "# make conversion map\n",
    "\n",
    "#merger_start_date = WHAT IS THIS? - date announced\n",
    "#merger_stop_date = WHAT IS THIS? - date completed\n",
    "\n",
    "conversion_map = get_conversion_map(code, info_dict[\"FinalUnits\"])\n",
    "    \n",
    "area_month_upc = aggregate_movement(code, years, groups, modules, \"month\", conversion_map, info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "\n",
    "area_month_upc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "starting-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded store file of 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded store file of 2012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>upc</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>sales</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channel_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1380014660</td>\n",
       "      <td>2012</td>\n",
       "      <td>5</td>\n",
       "      <td>109028.734981</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1380014660</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>242000.224296</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1380014660</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>106258.517529</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1380014660</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>154183.383295</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1380014660</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>268279.391223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>74215878775</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>178.199918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>74215878775</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>187.146732</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>74215878775</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>52.711117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>74215878775</td>\n",
       "      <td>2012</td>\n",
       "      <td>11</td>\n",
       "      <td>43.389920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>74215878775</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>54.728329</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      upc  year month          sales volume\n",
       "channel_code                                       F      F\n",
       "0              1380014660  2012     5  109028.734981    0.0\n",
       "1              1380014660  2012     6  242000.224296    0.0\n",
       "2              1380014660  2012     7  106258.517529    0.0\n",
       "3              1380014660  2012     8  154183.383295    0.0\n",
       "4              1380014660  2012     9  268279.391223    0.0\n",
       "..                    ...   ...   ...            ...    ...\n",
       "62            74215878775  2012     8     178.199918    0.0\n",
       "63            74215878775  2012     9     187.146732    0.0\n",
       "64            74215878775  2012    10      52.711117    0.0\n",
       "65            74215878775  2012    11      43.389920    0.0\n",
       "66            74215878775  2012    12      54.728329    0.0\n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating area_month_upc file\n",
    "area_month_upc = aggregate_movement(code, years, groups, modules, \"month\", conversion_map, info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "area_month_upc = area_month_upc[['store_code_uc', 'upc', 'year', 'month', 'sales', 'dma_code', 'volume']]\n",
    "\n",
    "# loading stores\n",
    "stores = load_store_table('2012')\n",
    "stores_dict = stores[['year','parent_code', 'retailer_code', 'channel_code', 'dma_code']].to_dict()\n",
    "\n",
    "# inserting store type\n",
    "area_month_upc.insert(1, \"channel_code\", area_month_upc[\"store_code_uc\"].map(stores_dict[\"channel_code\"]))\n",
    "area_month_upc.insert(1, \"parent_code\", area_month_upc[\"store_code_uc\"].map(stores_dict[\"parent_code\"]))\n",
    "\n",
    "area_month_upc = area_month_upc.groupby(['channel_code','upc','year','month']).agg({'sales': 'sum', 'volume': 'sum'})\n",
    "area_month_upc = area_month_upc.pivot_table(index = ['upc','year','month'], columns = 'channel_code', values = ['sales','volume'], fill_value = 0).reset_index()\n",
    "\n",
    "\n",
    "# basically - if SAME channel code for same upc-year-month combination, sum up sales and collapse into 1 row\n",
    "\n",
    "area_month_upc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "blind-webmaster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>upc</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>owner</th>\n",
       "      <th>sales</th>\n",
       "      <th>sales.1</th>\n",
       "      <th>sales.2</th>\n",
       "      <th>sales.3</th>\n",
       "      <th>sales.4</th>\n",
       "      <th>sales.5</th>\n",
       "      <th>...</th>\n",
       "      <th>volume.106</th>\n",
       "      <th>volume.107</th>\n",
       "      <th>volume.108</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>sold_in_usa</th>\n",
       "      <th>merging_party</th>\n",
       "      <th>post_merger</th>\n",
       "      <th>(sales, F)</th>\n",
       "      <th>(volume, F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.380015e+09</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NESTLE</td>\n",
       "      <td>970.190903</td>\n",
       "      <td>25394.511405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13102.286856</td>\n",
       "      <td>14015.961784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109028.734981</td>\n",
       "      <td>11772.218467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109028.734981</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.380015e+09</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NESTLE</td>\n",
       "      <td>2235.659374</td>\n",
       "      <td>53089.835259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30855.872625</td>\n",
       "      <td>27714.629707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242000.224296</td>\n",
       "      <td>26091.100869</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242000.224296</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.380015e+09</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NESTLE</td>\n",
       "      <td>755.884884</td>\n",
       "      <td>23744.233910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12642.174680</td>\n",
       "      <td>13010.668561</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106258.517529</td>\n",
       "      <td>11437.612862</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106258.517529</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.380015e+09</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NESTLE</td>\n",
       "      <td>1071.174703</td>\n",
       "      <td>32595.658276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20286.545465</td>\n",
       "      <td>17448.872130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154183.383295</td>\n",
       "      <td>16688.581670</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154183.383295</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.380015e+09</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NESTLE</td>\n",
       "      <td>2076.705090</td>\n",
       "      <td>59466.730900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35229.150318</td>\n",
       "      <td>31067.284543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268279.391223</td>\n",
       "      <td>29171.709917</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268279.391223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7.421588e+10</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>LOBLAW COMPANIES LIMITED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.199918</td>\n",
       "      <td>14.458245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.199918</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7.421588e+10</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LOBLAW COMPANIES LIMITED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.146732</td>\n",
       "      <td>15.308730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.146732</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>7.421588e+10</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>LOBLAW COMPANIES LIMITED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.711117</td>\n",
       "      <td>4.252425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.711117</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>7.421588e+10</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>LOBLAW COMPANIES LIMITED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.389920</td>\n",
       "      <td>3.401940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.389920</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7.421588e+10</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>LOBLAW COMPANIES LIMITED</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.728329</td>\n",
       "      <td>4.252425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.728329</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             upc    year  month                     owner        sales  \\\n",
       "0   1.380015e+09  2012.0    5.0                    NESTLE   970.190903   \n",
       "1   1.380015e+09  2012.0    6.0                    NESTLE  2235.659374   \n",
       "2   1.380015e+09  2012.0    7.0                    NESTLE   755.884884   \n",
       "3   1.380015e+09  2012.0    8.0                    NESTLE  1071.174703   \n",
       "4   1.380015e+09  2012.0    9.0                    NESTLE  2076.705090   \n",
       "..           ...     ...    ...                       ...          ...   \n",
       "62  7.421588e+10  2012.0    8.0  LOBLAW COMPANIES LIMITED     0.000000   \n",
       "63  7.421588e+10  2012.0    9.0  LOBLAW COMPANIES LIMITED     0.000000   \n",
       "64  7.421588e+10  2012.0   10.0  LOBLAW COMPANIES LIMITED     0.000000   \n",
       "65  7.421588e+10  2012.0   11.0  LOBLAW COMPANIES LIMITED     0.000000   \n",
       "66  7.421588e+10  2012.0   12.0  LOBLAW COMPANIES LIMITED     0.000000   \n",
       "\n",
       "         sales.1  sales.2       sales.3       sales.4  sales.5  ...  \\\n",
       "0   25394.511405      0.0  13102.286856  14015.961784      0.0  ...   \n",
       "1   53089.835259      0.0  30855.872625  27714.629707      0.0  ...   \n",
       "2   23744.233910      0.0  12642.174680  13010.668561      0.0  ...   \n",
       "3   32595.658276      0.0  20286.545465  17448.872130      0.0  ...   \n",
       "4   59466.730900      0.0  35229.150318  31067.284543      0.0  ...   \n",
       "..           ...      ...           ...           ...      ...  ...   \n",
       "62      0.000000      0.0      0.000000      0.000000      0.0  ...   \n",
       "63      0.000000      0.0      0.000000      0.000000      0.0  ...   \n",
       "64      0.000000      0.0      0.000000      0.000000      0.0  ...   \n",
       "65      0.000000      0.0      0.000000      0.000000      0.0  ...   \n",
       "66      0.000000      0.0      0.000000      0.000000      0.0  ...   \n",
       "\n",
       "    volume.106  volume.107  volume.108    total_sales  total_volume  \\\n",
       "0          0.0         0.0         0.0  109028.734981  11772.218467   \n",
       "1          0.0         0.0         0.0  242000.224296  26091.100869   \n",
       "2          0.0         0.0         0.0  106258.517529  11437.612862   \n",
       "3          0.0         0.0         0.0  154183.383295  16688.581670   \n",
       "4          0.0         0.0         0.0  268279.391223  29171.709917   \n",
       "..         ...         ...         ...            ...           ...   \n",
       "62         0.0         0.0         0.0     178.199918     14.458245   \n",
       "63         0.0         0.0         0.0     187.146732     15.308730   \n",
       "64         0.0         0.0         0.0      52.711117      4.252425   \n",
       "65         0.0         0.0         0.0      43.389920      3.401940   \n",
       "66         0.0         0.0         0.0      54.728329      4.252425   \n",
       "\n",
       "    sold_in_usa  merging_party  post_merger     (sales, F)  (volume, F)  \n",
       "0           1.0            0.0          0.0  109028.734981          0.0  \n",
       "1           1.0            0.0          0.0  242000.224296          0.0  \n",
       "2           1.0            0.0          0.0  106258.517529          0.0  \n",
       "3           1.0            0.0          0.0  154183.383295          0.0  \n",
       "4           1.0            0.0          0.0  268279.391223          0.0  \n",
       "..          ...            ...          ...            ...          ...  \n",
       "62          1.0            0.0          0.0     178.199918          0.0  \n",
       "63          1.0            0.0          0.0     187.146732          0.0  \n",
       "64          1.0            0.0          0.0      52.711117          0.0  \n",
       "65          1.0            0.0          0.0      43.389920          0.0  \n",
       "66          1.0            0.0          0.0      54.728329          0.0  \n",
       "\n",
       "[67 rows x 229 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = '2641303020_8'\n",
    "\n",
    "pivoted = pd.read_csv('m_' + code + '/pivoted_data.csv')\n",
    "pivoted\n",
    "area_month_upc\n",
    "\n",
    "final_table = pd.merge(pivoted, area_month_upc, how = \"right\", on = ['upc', 'year', 'month'])\n",
    "final_table.to_csv('final_table_try1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "removable-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "#area_month_upc_clean = area_month_upc_clean['channel_code'].map(stores_dict['channel_code'])\n",
    "#area_month_upc_clean['channel_code']\n",
    "#area_month_upc.insert(1, \"channel_code\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "manufactured-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded store file of 2012\n"
     ]
    }
   ],
   "source": [
    "stores = load_store_table('2012')\n",
    "stores.to_csv('stores_check.csv')\n",
    "\n",
    "stores = stores.sort_values(by = ['store_code_uc'])\n",
    "\n",
    "stores_dict = stores[['year','parent_code', 'retailer_code', 'channel_code', 'dma_code']].to_dict()\n",
    "\n",
    "#stores.columns()\n",
    "#stores['store']\n",
    "\n",
    "#stores_dict['channel_code']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
