{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "liked-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import time\n",
    "import pyblp\n",
    "import auxiliary as aux\n",
    "import sqldf\n",
    "import pysqldf as ps\n",
    "from pandasql import sqldf\n",
    "import pandasql\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from clean_data import clean_data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import first_task\n",
    "\n",
    "def parse_info(code):\n",
    "    file = open('../../../../All/m_' + code + '/info.txt', mode = 'r')\n",
    "    info_file = file.read()\n",
    "    file.close()\n",
    "\n",
    "    all_info_elements = re.finditer('\\[(.*?):(.*?)\\]', info_file, re.DOTALL)\n",
    "    info_dict = {}\n",
    "    for info in all_info_elements:\n",
    "        info_name = info.group(1).strip()\n",
    "        info_content = info.group(2).strip()\n",
    "        info_dict[info_name] = info_content\n",
    "    return info_dict\n",
    "\n",
    "def adjust_inflation(df, all_vars, month_or_quarter, rename_var = True):\n",
    "\n",
    "    # Import CPIU dataset\n",
    "    cpiu = pd.read_excel('../../../../All/master/cpiu_2000_2020.xlsx', header = 11)\n",
    "    cpiu = cpiu.set_index('Year')\n",
    "    month_dictionary = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "    cpiu = cpiu.rename(columns = month_dictionary)\n",
    "    cpiu = cpiu.drop(['HALF1','HALF2'], axis=1)\n",
    "    cpiu = cpiu.stack()\n",
    "\n",
    "    # Aggregate to the quarter level, if necessary\n",
    "    cpiu = cpiu.reset_index().rename(columns = {'level_1':'month',0:'cpiu'})\n",
    "    if month_or_quarter == 'quarter':\n",
    "        cpiu['quarter'] = cpiu['month'].apply(lambda x: 1 if x <=3 else 2 if ((x>3) & (x<=6)) else 3 if ((x>6) & (x<=9)) else 4)\n",
    "        cpiu = cpiu.groupby(['Year', month_or_quarter]).agg({'cpiu': 'mean'}).reset_index()\n",
    "    if month_or_quarter == 'month':\n",
    "        cpiu = cpiu.set_index(['Year', month_or_quarter]).reset_index()\n",
    "\n",
    "    # Set index value in base period\n",
    "    cpiu['cpiu_201001'] = float(cpiu.loc[(cpiu['Year'] == 2010) & (cpiu[month_or_quarter]==1),'cpiu'])\n",
    "    cpiu = cpiu.rename(columns={'Year': 'year'})\n",
    "    cpiu = cpiu.set_index(['year', month_or_quarter])\n",
    "\n",
    "    # Merge CPIU onto dataframe and adjust prices\n",
    "    df = df.join(cpiu, on=['year', month_or_quarter], how = 'left')\n",
    "    for var in all_vars:\n",
    "        if rename_var:\n",
    "            df[var] = df[var] * (df['cpiu_201001'] / df['cpiu'])\n",
    "        else:\n",
    "            df[var + '_adj'] = df[var] * df['cpiu_201001'] / df['cpiu']\n",
    "    df = df.drop(['cpiu_201001', 'cpiu'], axis = 1)\n",
    "    return df\n",
    "\n",
    "def get_date_range(initial_year_string, final_year_string, pre_months = 24, post_months = 24):\n",
    "        initial_dt = datetime.strptime(initial_year_string, '%Y-%m-%d')\n",
    "        final_dt = datetime.strptime(final_year_string, '%Y-%m-%d')\n",
    "        initial_month_int = initial_dt.year * 12 + initial_dt.month\n",
    "        final_month_int = final_dt.year * 12 + final_dt.month\n",
    "        min_year, min_month = int_to_month(initial_month_int - pre_months)\n",
    "        max_year, max_month = int_to_month(final_month_int + post_months)\n",
    "\n",
    "        string_init = str(int(min_year)) + \"-\" + str(int(min_month))\n",
    "        string_final = str(int(max_year)) + \"-\" + str(int(max_month))\n",
    "        years_range = pd.date_range(string_init, string_final, freq='MS').strftime(\"%Y\").tolist()\n",
    "        months_range = pd.date_range(string_init, string_final, freq='MS').strftime(\"%m\").tolist()\n",
    "\n",
    "        date_range = pd.DataFrame(zip(years_range, months_range))\n",
    "\n",
    "        return date_range\n",
    "    \n",
    "def load_store_table(year):\n",
    "    store_path = \"../../../../Data/nielsen_extracts/RMS/\" + year + \"/Annual_Files/stores_\" + year + \".tsv\"\n",
    "    store_table = pd.read_csv(store_path, delimiter = \"\\t\", index_col = \"store_code_uc\")\n",
    "    print(\"Loaded store file of \"+ year)\n",
    "    return store_table\n",
    "\n",
    "def get_product_map(groups):\n",
    "    products_path = \"../../../../Data/nielsen_extracts/RMS/Master_Files/Latest/products.tsv\"\n",
    "    products = pd.read_csv(products_path, delimiter = \"\\t\", encoding = \"cp1252\", header = 0, index_col = [\"upc\",\"upc_ver_uc\"])\n",
    "    int_groups = [int(i) for i in groups]\n",
    "    wanted_products = products[products['product_group_code'].isin(int_groups)]\n",
    "    product_map = wanted_products\n",
    "    return product_map\n",
    "\n",
    "def get_upc_ver_uc_map(year):\n",
    "    upc_ver_path = \"../../../../Data/nielsen_extracts/RMS/\"+str(year)+\"/Annual_Files/rms_versions_\"+str(year)+\".tsv\"\n",
    "    upc_vers = pd.read_csv(upc_ver_path, delimiter = \"\\t\", encoding = \"cp1252\", header = 0, index_col = \"upc\")\n",
    "    upc_vers = upc_vers['upc_ver_uc']\n",
    "    upc_ver_map = upc_vers.to_dict()\n",
    "    return upc_ver_map\n",
    "\n",
    "def get_conversion_map(code, final_unit, method = 'mode'):\n",
    "    # Get in the conversion map -- size1_units, multiplication\n",
    "    master_conversion = pd.read_csv('../../../../All/master/unit_conversion.csv')\n",
    "    assert master_conversion['final_unit'].str.contains(final_unit).any(), \"Cannot find %r as a final_unit\" % final_unit\n",
    "    master_conversion = master_conversion[master_conversion['final_unit'] == final_unit]\n",
    "\n",
    "    these_units = pd.read_csv('../../../../All/m_' + code + '/properties/units_edited.csv')\n",
    "    these_units['conversion'] = 0\n",
    "\n",
    "    # Anything that has convert = 1 must be in the master folder\n",
    "    convertible = these_units.loc[these_units.convert == 1].copy()\n",
    "    for this_unit in convertible.units.unique():\n",
    "        assert master_conversion['initial_unit'].str.contains(this_unit).any(), \"Cannot find %r as an initial_unit\" % this_unit\n",
    "        if this_unit in master_conversion.initial_unit.unique():\n",
    "            convert_factor = master_conversion.conversion[master_conversion.initial_unit == this_unit].values\n",
    "            these_units.loc[these_units.units == this_unit, 'conversion'] = convert_factor\n",
    "            convertible.loc[convertible.units == this_unit, 'conversion'] = convert_factor\n",
    "\n",
    "    # Convert the total quantity\n",
    "    convertible['total_quantity'] = convertible['total_quantity'] * convertible['conversion']\n",
    "\n",
    "    # The \"method\" for convert = 0 is mapped to the \"method\" for the convert = 1\n",
    "    # with the largest quantity\n",
    "    where_largest = convertible.total_quantity.idxmax()\n",
    "    if method == 'mode':\n",
    "        base_size = convertible.loc[where_largest]['mode']\n",
    "        other_size = these_units[these_units.convert == 0]['mode']\n",
    "    else:\n",
    "        base_size = convertible.loc[where_largest]['median']\n",
    "        other_size = these_units[these_units.convert == 0]['median']\n",
    "\n",
    "    these_units.conversion[these_units.convert == 0] = convertible.conversion[where_largest] * base_size / other_size\n",
    "    these_units = these_units[['units', 'conversion']]\n",
    "    these_units = these_units.rename(columns = {'units' : 'size1_units'})\n",
    "    these_units = these_units.set_index('size1_units')\n",
    "\n",
    "    conversion_map = these_units.to_dict()\n",
    "    return conversion_map\n",
    "def load_chunked_year_module_movement_table(year, group, module, path = ''):\n",
    "    if path == '':\n",
    "        path = \"../../../../Data/nielsen_extracts/RMS/\" + year + \"/Movement_Files/\" + group + \"_\" + year + \"/\" + module + \"_\" + year + \".tsv\"\n",
    "    assert os.path.exists(path), \"File does not exist: %r\" % path\n",
    "    table = pd.read_csv(path, delimiter = \"\\t\", chunksize = 10000000)\n",
    "    return table\n",
    "\n",
    "def aggregate_movement(code, years, groups, modules, month_or_quarter, conversion_map, merger_start_date, merger_stop_date, market_size_scale = 1.5, pre_months = 24, post_months = 24):\n",
    "\n",
    "    # Get the relevant range\n",
    "    stop_dt = datetime.strptime(merger_stop_date, '%Y-%m-%d')\n",
    "    start_dt = datetime.strptime(merger_start_date, '%Y-%m-%d')\n",
    "    stop_month_int = stop_dt.year * 12 + stop_dt.month\n",
    "    start_month_int = start_dt.year * 12 + start_dt.month\n",
    "\n",
    "    min_year, min_month = aux.int_to_month(start_month_int - pre_months)\n",
    "    max_year, max_month = aux.int_to_month(stop_month_int + post_months)\n",
    "    min_quarter = np.ceil(min_month/3)\n",
    "    max_quarter = np.ceil(max_month/3)\n",
    "\n",
    "    #manual fix for baby strained food\n",
    "    if ((code=='1817013020_3') & (max_year > 2008)):\n",
    "        max_year = 2008\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2008, years))\n",
    "\n",
    "    #manual fix for bread\n",
    "    if ((code=='2203820020_1') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for buns\n",
    "    if ((code=='2203820020_2') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for rolls\n",
    "    if ((code=='2203820020_3') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for pies\n",
    "    if ((code=='2203820020_8') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for bakery remaining\n",
    "    if ((code=='2203820020_10') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for cheesecake\n",
    "    if ((code=='2203820020_11') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for biscuits\n",
    "    if ((code=='2203820020_12') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "        #manual fix for RBC_Bread\n",
    "    if ((code=='2033113020_2') & (min_year < 2007)):\n",
    "        min_year = 2007\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2007, years))\n",
    "\n",
    "        #manual fix for RBC_Cake\n",
    "    if ((code=='2033113020_3') & (min_year < 2007)):\n",
    "        min_year = 2007\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2007, years))\n",
    "\n",
    "        #manual fix for Headache pills\n",
    "    if ((code=='2373087020_1') & (min_year < 2010)):\n",
    "        min_year = 2010\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2010, years))\n",
    "\n",
    "        #manual fix for School and Office Supplies\n",
    "    if ((code=='2363232020_4') & (min_year < 2010)):\n",
    "        min_year = 2010\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2010, years))\n",
    "\n",
    "    area_time_upc_list = []\n",
    "    product_map = get_product_map(list(set(groups)))\n",
    "    add_from_map = ['brand_code_uc', 'brand_descr', 'multi', 'size1_units', 'size1_amount']\n",
    "    aggregation_function = {'week_end' : 'first', 'units' : 'sum', 'prmult' : 'mean', 'price' : 'mean', 'feature' : 'first', 'display' : 'first', 'store_code_uc' : 'first', 'sales' : 'sum', 'module' : 'first'}\n",
    "\n",
    "    #for year in years:\n",
    "    store_table = load_store_table(year)\n",
    "    store_map = store_table.to_dict()\n",
    "    dma_map = store_map['dma_code']\n",
    "    upc_ver_map = get_upc_ver_uc_map(year)\n",
    "\n",
    "    for group, module in zip(groups, modules):\n",
    "        movement_table = load_chunked_year_module_movement_table(year, group, module)\n",
    "\n",
    "        for data_chunk in tqdm(movement_table):\n",
    "            data_chunk['year'] = np.floor(data_chunk['week_end']/10000)\n",
    "            data_chunk['year'] = data_chunk['year'].astype(int)\n",
    "            if month_or_quarter == \"month\":\n",
    "                data_chunk[month_or_quarter] = np.floor((data_chunk['week_end'] % 10000)/100)\n",
    "                data_chunk[month_or_quarter] = data_chunk[month_or_quarter].astype(int)\n",
    "\n",
    "                if int(year) == min_year:\n",
    "                    data_chunk = data_chunk[data_chunk.month >= min_month]\n",
    "                elif int(year) == max_year:\n",
    "                    data_chunk = data_chunk[data_chunk.month <= max_month]\n",
    "            elif month_or_quarter == \"quarter\":\n",
    "                data_chunk[month_or_quarter] = np.ceil(np.floor((data_chunk['week_end'] % 10000)/100)/3)\n",
    "                data_chunk[month_or_quarter] = data_chunk[month_or_quarter].astype(int)\n",
    "                if int(year) == min_year:\n",
    "                    data_chunk = data_chunk[data_chunk.quarter >= min_quarter]\n",
    "                elif int(year) == max_year:\n",
    "                    data_chunk = data_chunk[data_chunk.quarter <= max_quarter]\n",
    "\n",
    "            data_chunk['dma_code'] = data_chunk['store_code_uc'].map(dma_map)\n",
    "            data_chunk['sales'] = data_chunk['price'] * data_chunk['units'] / data_chunk['prmult']\n",
    "            data_chunk['module'] = int(module)\n",
    "            data_chunk['upc_ver_uc'] = data_chunk['upc'].map(upc_ver_map)\n",
    "            area_time_upc = data_chunk.groupby(['year', month_or_quarter, 'upc', 'upc_ver_uc', 'dma_code'], as_index = False).aggregate(aggregation_function).reindex(columns = data_chunk.columns)\n",
    "            area_time_upc_list.append(area_time_upc)\n",
    "\n",
    "    area_time_upc = pd.concat(area_time_upc_list)\n",
    "    area_time_upc = area_time_upc.groupby(['year', month_or_quarter, 'upc', 'upc_ver_uc', 'dma_code'], as_index = False).aggregate(aggregation_function).reindex(columns = area_time_upc.columns)\n",
    "    area_time_upc = area_time_upc.join(product_map[add_from_map], on=['upc','upc_ver_uc'], how='left')\n",
    "    area_time_upc = clean_data(code, area_time_upc)\n",
    "    area_time_upc['conversion'] = area_time_upc['size1_units'].map(conversion_map['conversion'])\n",
    "    area_time_upc['volume'] = area_time_upc['units'] * area_time_upc['size1_amount'] * area_time_upc['multi'] * area_time_upc['conversion']\n",
    "    area_time_upc['prices'] = area_time_upc['sales'] / area_time_upc['volume']\n",
    "    \n",
    "    area_time_upc.drop(['week_end'], axis=1, inplace=True)\n",
    "\n",
    "    # Normalize the prices by the CPI.  Let January 2010 = 1.\n",
    "    area_time_upc = adjust_inflation(area_time_upc, ['prices', 'sales'], month_or_quarter)\n",
    "\n",
    "    # Get the market sizes here, by summing volume within dma-time and then taking 1.5 times max within-dma\n",
    "    short_area_time_upc = area_time_upc[['dma_code', 'year', month_or_quarter, 'volume', 'sales']]\n",
    "    market_sizes = short_area_time_upc.groupby(['dma_code', 'year', month_or_quarter]).sum()\n",
    "    market_sizes['market_size'] = market_size_scale * market_sizes['volume'].groupby('dma_code').transform('max')\n",
    "    market_sizes = market_sizes.rename(columns = {'sales': 'total_sales', 'volume' : 'total_volume'})\n",
    "\n",
    "    # Save the output if this is month\n",
    "    if month_or_quarter == 'month':\n",
    "        market_sizes.to_csv('../../../../All/m_' + code + '/intermediate/market_sizes.csv', sep = ',', encoding = 'utf-8')\n",
    "\n",
    "    # Shares = volume / market size.  Map market sizes back and get shares.\n",
    "    area_time_upc = area_time_upc.join(market_sizes.drop('total_volume', axis=1), on = ['dma_code', 'year', month_or_quarter])\n",
    "    area_time_upc['shares'] = area_time_upc['volume'] / area_time_upc['market_size']\n",
    "\n",
    "    return area_time_upc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "automotive-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded store file of 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['store_code_uc', 'upc', 'units', 'prmult', 'price', 'feature',\n",
       "       'display', 'year', 'month', 'dma_code', 'sales', 'module', 'upc_ver_uc',\n",
       "       'brand_code_uc', 'brand_descr', 'multi', 'size1_units', 'size1_amount',\n",
       "       'conversion', 'volume', 'prices', 'total_sales', 'market_size',\n",
       "       'shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### objective of this is to get area_month_upc BECAUSE THIS HAS STORE UC CODES!\n",
    "\n",
    "#setup\n",
    "code = '2641303020_8'\n",
    "info_dict = parse_info(code)\n",
    "info_dict.keys()\n",
    "final_unit = info_dict['FinalUnits']\n",
    "\n",
    "groups, modules = aux.get_groups_and_modules(info_dict[\"MarketDefinition\"])\n",
    "# FIXUP for 1 year\n",
    "#years = aux.get_years(info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "years = 2012\n",
    "year = '2012'\n",
    "\n",
    "# make conversion map\n",
    "\n",
    "#merger_start_date = WHAT IS THIS? - date announced\n",
    "#merger_stop_date = WHAT IS THIS? - date completed\n",
    "\n",
    "conversion_map = get_conversion_map(code, info_dict[\"FinalUnits\"])\n",
    "    \n",
    "area_month_upc = aggregate_movement(code, years, groups, modules, \"month\", conversion_map, info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "\n",
    "area_month_upc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "starting-lewis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>upc</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>owner</th>\n",
       "      <th colspan=\"6\" halign=\"left\">sales</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">volume</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>sold_in_usa</th>\n",
       "      <th>merging_party</th>\n",
       "      <th>post_merger</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dma_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>...</th>\n",
       "      <th>855</th>\n",
       "      <th>862</th>\n",
       "      <th>866</th>\n",
       "      <th>868</th>\n",
       "      <th>881</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2150000064</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>Unilever-Lawry's and Adolph's</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2150000064</td>\n",
       "      <td>2005</td>\n",
       "      <td>12</td>\n",
       "      <td>Unilever-Lawry's and Adolph's</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2150000064</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>Unilever-Lawry's and Adolph's</td>\n",
       "      <td>89.155282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.487926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.961525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>187.560292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.782904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52042.010733</td>\n",
       "      <td>1946.136476</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2150000064</td>\n",
       "      <td>2006</td>\n",
       "      <td>2</td>\n",
       "      <td>Unilever-Lawry's and Adolph's</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>403.831721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.989194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.720764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53.977448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.329312</td>\n",
       "      <td>21287.027714</td>\n",
       "      <td>859.556840</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2150000064</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>Unilever-Lawry's and Adolph's</td>\n",
       "      <td>73.378591</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.502268</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138.124406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>216.023190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.999212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55985.912562</td>\n",
       "      <td>2019.391584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>947582845316</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>Several owners</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13919.169621</td>\n",
       "      <td>1606.622864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>947582845316</td>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>Several owners</td>\n",
       "      <td>1036.180156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.504413</td>\n",
       "      <td>110.678434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4451.370596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15200.487079</td>\n",
       "      <td>1565.572788</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>947582845316</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>Several owners</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13710.417220</td>\n",
       "      <td>1578.500160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>947582845316</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>Several owners</td>\n",
       "      <td>992.426082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.492035</td>\n",
       "      <td>96.917813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3942.480671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13909.470412</td>\n",
       "      <td>1430.629168</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>947582845316</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>Several owners</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14655.772024</td>\n",
       "      <td>1696.660876</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1102 rows Ã— 393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   upc  year month                          owner  \\\n",
       "dma_code                                                            \n",
       "0           2150000064  2005    11  Unilever-Lawry's and Adolph's   \n",
       "1           2150000064  2005    12  Unilever-Lawry's and Adolph's   \n",
       "2           2150000064  2006     1  Unilever-Lawry's and Adolph's   \n",
       "3           2150000064  2006     2  Unilever-Lawry's and Adolph's   \n",
       "4           2150000064  2006     3  Unilever-Lawry's and Adolph's   \n",
       "...                ...   ...   ...                            ...   \n",
       "1097      947582845316  2010     4                 Several owners   \n",
       "1098      947582845316  2010     5                 Several owners   \n",
       "1099      947582845316  2010     6                 Several owners   \n",
       "1100      947582845316  2010     7                 Several owners   \n",
       "1101      947582845316  2010     8                 Several owners   \n",
       "\n",
       "                sales                                               \\\n",
       "dma_code          500         501        503         504       505   \n",
       "0            0.000000    0.000000   0.000000    0.000000  0.000000   \n",
       "1            0.000000    0.000000   0.000000    0.000000  0.000000   \n",
       "2           89.155282    0.000000   0.000000   24.487926  0.000000   \n",
       "3            0.000000  403.831721   0.000000    0.000000  9.989194   \n",
       "4           73.378591    0.000000   0.000000   13.502268  0.000000   \n",
       "...               ...         ...        ...         ...       ...   \n",
       "1097         0.000000    0.000000   0.000000    0.000000  0.000000   \n",
       "1098      1036.180156    0.000000  41.504413  110.678434  0.000000   \n",
       "1099         0.000000    0.000000   0.000000    0.000000  0.000000   \n",
       "1100       992.426082    0.000000  45.492035   96.917813  0.000000   \n",
       "1101         0.000000    0.000000   0.000000    0.000000  0.000000   \n",
       "\n",
       "                       ...     volume                                    \\\n",
       "dma_code          506  ...        855         862        866        868   \n",
       "0            0.000000  ...   0.000000    0.000000   0.000000   0.000000   \n",
       "1            0.000000  ...   0.000000    0.000000   0.000000   0.000000   \n",
       "2          173.961525  ...   0.000000  187.560292   0.000000  16.782904   \n",
       "3            0.000000  ...  24.720764    0.000000  53.977448   0.000000   \n",
       "4          138.124406  ...   0.000000  216.023190   0.000000  21.999212   \n",
       "...               ...  ...        ...         ...        ...        ...   \n",
       "1097         0.000000  ...   0.000000    0.000000   0.000000   0.000000   \n",
       "1098      4451.370596  ...   0.000000    0.000000   0.000000   0.000000   \n",
       "1099         0.000000  ...   0.000000    0.000000   0.000000   0.000000   \n",
       "1100      3942.480671  ...   0.000000    0.000000   0.000000   0.000000   \n",
       "1101         0.000000  ...   0.000000    0.000000   0.000000   0.000000   \n",
       "\n",
       "                      total_sales total_volume sold_in_usa merging_party  \\\n",
       "dma_code        881                                                        \n",
       "0          0.000000      0.000000     0.000000           0             1   \n",
       "1          0.000000      0.000000     0.000000           0             1   \n",
       "2          0.000000  52042.010733  1946.136476           1             1   \n",
       "3         16.329312  21287.027714   859.556840           1             1   \n",
       "4          0.000000  55985.912562  2019.391584           1             1   \n",
       "...             ...           ...          ...         ...           ...   \n",
       "1097       0.000000  13919.169621  1606.622864           1             0   \n",
       "1098       0.000000  15200.487079  1565.572788           1             0   \n",
       "1099       0.000000  13710.417220  1578.500160           1             0   \n",
       "1100       0.000000  13909.470412  1430.629168           1             0   \n",
       "1101       0.000000  14655.772024  1696.660876           1             0   \n",
       "\n",
       "         post_merger  \n",
       "dma_code              \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1097               0  \n",
       "1098               0  \n",
       "1099               0  \n",
       "1100               0  \n",
       "1101               0  \n",
       "\n",
       "[1102 rows x 393 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating area_month_upc file\n",
    "area_month_upc = aggregate_movement(code, years, groups, modules, \"month\", conversion_map, info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "area_month_upc = area_month_upc[['store_code_uc', 'upc', 'year', 'month', 'sales', 'dma_code', 'volume']]\n",
    "\n",
    "# loading stores\n",
    "stores = load_store_table('2012')\n",
    "stores_dict = stores[['year','parent_code', 'retailer_code', 'channel_code', 'dma_code']].to_dict()\n",
    "\n",
    "# inserting store type\n",
    "area_month_upc.insert(1, \"channel_code\", area_month_upc[\"store_code_uc\"].map(stores_dict[\"channel_code\"]))\n",
    "area_month_upc.insert(1, \"parent_code\", area_month_upc[\"store_code_uc\"].map(stores_dict[\"parent_code\"]))\n",
    "\n",
    "area_month_upc = area_month_upc.groupby(['channel_code','upc','year','month']).agg({'sales': 'sum', 'volume': 'sum'})\n",
    "area_month_upc = area_month_upc.pivot_table(index = ['upc','year','month'], columns = 'channel_code', values = ['sales','volume'], fill_value = 0).reset_index()\n",
    "\n",
    "\n",
    "# basically - if SAME channel code for same upc-year-month combination, sum up sales and collapse into 1 row\n",
    "\n",
    "#area_month_upc\n",
    "table_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "prostate-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '1924129020_1'\n",
    "\n",
    "info_dict = parse_info(code)\n",
    "\n",
    "conversion_map = get_conversion_map(code, info_dict['FinalUnits'], method = 'mode')\n",
    "\n",
    "groups, modules = aux.get_groups_and_modules(info_dict[\"MarketDefinition\"])\n",
    "\n",
    "info_dict['DateAnnounced']\n",
    "\n",
    "years = 2006\n",
    "year = '2006' \n",
    "\n",
    "area_month_upc = aggregate_movement(code, years, groups, modules, 'month', conversion_map, info_dict['DateAnnounced'], info_dict['DateCompleted'], market_size_scale = 1.5, pre_months = 24, post_months = 24)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "greatest-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = first_task.table_1(code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
