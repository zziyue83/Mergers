{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "liked-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import time\n",
    "import pyblp\n",
    "import auxiliary as aux\n",
    "import sqldf\n",
    "import pysqldf as ps\n",
    "from pandasql import sqldf\n",
    "import pandasql\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from clean_data import clean_data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def parse_info(code):\n",
    "    file = open('../../../../All/m_' + code + '/info.txt', mode = 'r')\n",
    "    info_file = file.read()\n",
    "    file.close()\n",
    "\n",
    "    all_info_elements = re.finditer('\\[(.*?):(.*?)\\]', info_file, re.DOTALL)\n",
    "    info_dict = {}\n",
    "    for info in all_info_elements:\n",
    "        info_name = info.group(1).strip()\n",
    "        info_content = info.group(2).strip()\n",
    "        info_dict[info_name] = info_content\n",
    "    return info_dict\n",
    "\n",
    "def adjust_inflation(df, all_vars, month_or_quarter, rename_var = True):\n",
    "\n",
    "    # Import CPIU dataset\n",
    "    cpiu = pd.read_excel('../../../../All/master/cpiu_2000_2020.xlsx', header = 11)\n",
    "    cpiu = cpiu.set_index('Year')\n",
    "    month_dictionary = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "    cpiu = cpiu.rename(columns = month_dictionary)\n",
    "    cpiu = cpiu.drop(['HALF1','HALF2'], axis=1)\n",
    "    cpiu = cpiu.stack()\n",
    "\n",
    "    # Aggregate to the quarter level, if necessary\n",
    "    cpiu = cpiu.reset_index().rename(columns = {'level_1':'month',0:'cpiu'})\n",
    "    if month_or_quarter == 'quarter':\n",
    "        cpiu['quarter'] = cpiu['month'].apply(lambda x: 1 if x <=3 else 2 if ((x>3) & (x<=6)) else 3 if ((x>6) & (x<=9)) else 4)\n",
    "        cpiu = cpiu.groupby(['Year', month_or_quarter]).agg({'cpiu': 'mean'}).reset_index()\n",
    "    if month_or_quarter == 'month':\n",
    "        cpiu = cpiu.set_index(['Year', month_or_quarter]).reset_index()\n",
    "\n",
    "    # Set index value in base period\n",
    "    cpiu['cpiu_201001'] = float(cpiu.loc[(cpiu['Year'] == 2010) & (cpiu[month_or_quarter]==1),'cpiu'])\n",
    "    cpiu = cpiu.rename(columns={'Year': 'year'})\n",
    "    cpiu = cpiu.set_index(['year', month_or_quarter])\n",
    "\n",
    "    # Merge CPIU onto dataframe and adjust prices\n",
    "    df = df.join(cpiu, on=['year', month_or_quarter], how = 'left')\n",
    "    for var in all_vars:\n",
    "        if rename_var:\n",
    "            df[var] = df[var] * (df['cpiu_201001'] / df['cpiu'])\n",
    "        else:\n",
    "            df[var + '_adj'] = df[var] * df['cpiu_201001'] / df['cpiu']\n",
    "    df = df.drop(['cpiu_201001', 'cpiu'], axis = 1)\n",
    "    return df\n",
    "\n",
    "def get_date_range(initial_year_string, final_year_string, pre_months = 24, post_months = 24):\n",
    "        initial_dt = datetime.strptime(initial_year_string, '%Y-%m-%d')\n",
    "        final_dt = datetime.strptime(final_year_string, '%Y-%m-%d')\n",
    "        initial_month_int = initial_dt.year * 12 + initial_dt.month\n",
    "        final_month_int = final_dt.year * 12 + final_dt.month\n",
    "        min_year, min_month = int_to_month(initial_month_int - pre_months)\n",
    "        max_year, max_month = int_to_month(final_month_int + post_months)\n",
    "\n",
    "        string_init = str(int(min_year)) + \"-\" + str(int(min_month))\n",
    "        string_final = str(int(max_year)) + \"-\" + str(int(max_month))\n",
    "        years_range = pd.date_range(string_init, string_final, freq='MS').strftime(\"%Y\").tolist()\n",
    "        months_range = pd.date_range(string_init, string_final, freq='MS').strftime(\"%m\").tolist()\n",
    "\n",
    "        date_range = pd.DataFrame(zip(years_range, months_range))\n",
    "\n",
    "        return date_range\n",
    "    \n",
    "def load_store_table(year):\n",
    "    store_path = \"../../../../Data/nielsen_extracts/RMS/\" + year + \"/Annual_Files/stores_\" + year + \".tsv\"\n",
    "    store_table = pd.read_csv(store_path, delimiter = \"\\t\", index_col = \"store_code_uc\")\n",
    "    print(\"Loaded store file of \"+ year)\n",
    "    return store_table\n",
    "\n",
    "def get_product_map(groups):\n",
    "    products_path = \"../../../../Data/nielsen_extracts/RMS/Master_Files/Latest/products.tsv\"\n",
    "    products = pd.read_csv(products_path, delimiter = \"\\t\", encoding = \"cp1252\", header = 0, index_col = [\"upc\",\"upc_ver_uc\"])\n",
    "    int_groups = [int(i) for i in groups]\n",
    "    wanted_products = products[products['product_group_code'].isin(int_groups)]\n",
    "    product_map = wanted_products\n",
    "    return product_map\n",
    "\n",
    "def get_upc_ver_uc_map(year):\n",
    "    upc_ver_path = \"../../../../Data/nielsen_extracts/RMS/\"+str(year)+\"/Annual_Files/rms_versions_\"+str(year)+\".tsv\"\n",
    "    upc_vers = pd.read_csv(upc_ver_path, delimiter = \"\\t\", encoding = \"cp1252\", header = 0, index_col = \"upc\")\n",
    "    upc_vers = upc_vers['upc_ver_uc']\n",
    "    upc_ver_map = upc_vers.to_dict()\n",
    "    return upc_ver_map\n",
    "\n",
    "def get_conversion_map(code, final_unit, method = 'mode'):\n",
    "    # Get in the conversion map -- size1_units, multiplication\n",
    "    master_conversion = pd.read_csv('../../../../All/master/unit_conversion.csv')\n",
    "    assert master_conversion['final_unit'].str.contains(final_unit).any(), \"Cannot find %r as a final_unit\" % final_unit\n",
    "    master_conversion = master_conversion[master_conversion['final_unit'] == final_unit]\n",
    "\n",
    "    these_units = pd.read_csv('../../../../All/m_' + code + '/properties/units_edited.csv')\n",
    "    these_units['conversion'] = 0\n",
    "\n",
    "    # Anything that has convert = 1 must be in the master folder\n",
    "    convertible = these_units.loc[these_units.convert == 1].copy()\n",
    "    for this_unit in convertible.units.unique():\n",
    "        assert master_conversion['initial_unit'].str.contains(this_unit).any(), \"Cannot find %r as an initial_unit\" % this_unit\n",
    "        if this_unit in master_conversion.initial_unit.unique():\n",
    "            convert_factor = master_conversion.conversion[master_conversion.initial_unit == this_unit].values\n",
    "            these_units.loc[these_units.units == this_unit, 'conversion'] = convert_factor\n",
    "            convertible.loc[convertible.units == this_unit, 'conversion'] = convert_factor\n",
    "\n",
    "    # Convert the total quantity\n",
    "    convertible['total_quantity'] = convertible['total_quantity'] * convertible['conversion']\n",
    "\n",
    "    # The \"method\" for convert = 0 is mapped to the \"method\" for the convert = 1\n",
    "    # with the largest quantity\n",
    "    where_largest = convertible.total_quantity.idxmax()\n",
    "    if method == 'mode':\n",
    "        base_size = convertible.loc[where_largest]['mode']\n",
    "        other_size = these_units[these_units.convert == 0]['mode']\n",
    "    else:\n",
    "        base_size = convertible.loc[where_largest]['median']\n",
    "        other_size = these_units[these_units.convert == 0]['median']\n",
    "\n",
    "    these_units.conversion[these_units.convert == 0] = convertible.conversion[where_largest] * base_size / other_size\n",
    "    these_units = these_units[['units', 'conversion']]\n",
    "    these_units = these_units.rename(columns = {'units' : 'size1_units'})\n",
    "    these_units = these_units.set_index('size1_units')\n",
    "\n",
    "    conversion_map = these_units.to_dict()\n",
    "    return conversion_map\n",
    "def load_chunked_year_module_movement_table(year, group, module, path = ''):\n",
    "    if path == '':\n",
    "        path = \"../../../../Data/nielsen_extracts/RMS/\" + year + \"/Movement_Files/\" + group + \"_\" + year + \"/\" + module + \"_\" + year + \".tsv\"\n",
    "    assert os.path.exists(path), \"File does not exist: %r\" % path\n",
    "    table = pd.read_csv(path, delimiter = \"\\t\", chunksize = 10000000)\n",
    "    return table\n",
    "\n",
    "def aggregate_movement(code, years, groups, modules, month_or_quarter, conversion_map, merger_start_date, merger_stop_date, market_size_scale = 1.5, pre_months = 24, post_months = 24):\n",
    "\n",
    "    # Get the relevant range\n",
    "    stop_dt = datetime.strptime(merger_stop_date, '%Y-%m-%d')\n",
    "    start_dt = datetime.strptime(merger_start_date, '%Y-%m-%d')\n",
    "    stop_month_int = stop_dt.year * 12 + stop_dt.month\n",
    "    start_month_int = start_dt.year * 12 + start_dt.month\n",
    "\n",
    "    min_year, min_month = aux.int_to_month(start_month_int - pre_months)\n",
    "    max_year, max_month = aux.int_to_month(stop_month_int + post_months)\n",
    "    min_quarter = np.ceil(min_month/3)\n",
    "    max_quarter = np.ceil(max_month/3)\n",
    "\n",
    "    #manual fix for baby strained food\n",
    "    if ((code=='1817013020_3') & (max_year > 2008)):\n",
    "        max_year = 2008\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2008, years))\n",
    "\n",
    "    #manual fix for bread\n",
    "    if ((code=='2203820020_1') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for buns\n",
    "    if ((code=='2203820020_2') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for rolls\n",
    "    if ((code=='2203820020_3') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for pies\n",
    "    if ((code=='2203820020_8') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for bakery remaining\n",
    "    if ((code=='2203820020_10') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for cheesecake\n",
    "    if ((code=='2203820020_11') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for biscuits\n",
    "    if ((code=='2203820020_12') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "        #manual fix for RBC_Bread\n",
    "    if ((code=='2033113020_2') & (min_year < 2007)):\n",
    "        min_year = 2007\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2007, years))\n",
    "\n",
    "        #manual fix for RBC_Cake\n",
    "    if ((code=='2033113020_3') & (min_year < 2007)):\n",
    "        min_year = 2007\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2007, years))\n",
    "\n",
    "        #manual fix for Headache pills\n",
    "    if ((code=='2373087020_1') & (min_year < 2010)):\n",
    "        min_year = 2010\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2010, years))\n",
    "\n",
    "        #manual fix for School and Office Supplies\n",
    "    if ((code=='2363232020_4') & (min_year < 2010)):\n",
    "        min_year = 2010\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2010, years))\n",
    "\n",
    "    area_time_upc_list = []\n",
    "    product_map = get_product_map(list(set(groups)))\n",
    "    add_from_map = ['brand_code_uc', 'brand_descr', 'multi', 'size1_units', 'size1_amount']\n",
    "    aggregation_function = {'week_end' : 'first', 'units' : 'sum', 'prmult' : 'mean', 'price' : 'mean', 'feature' : 'first', 'display' : 'first', 'store_code_uc' : 'first', 'sales' : 'sum', 'module' : 'first'}\n",
    "\n",
    "    #for year in years:\n",
    "    store_table = load_store_table(year)\n",
    "    store_map = store_table.to_dict()\n",
    "    dma_map = store_map['dma_code']\n",
    "    upc_ver_map = get_upc_ver_uc_map(year)\n",
    "\n",
    "    for group, module in zip(groups, modules):\n",
    "        movement_table = load_chunked_year_module_movement_table(year, group, module)\n",
    "\n",
    "        for data_chunk in tqdm(movement_table):\n",
    "            data_chunk['year'] = np.floor(data_chunk['week_end']/10000)\n",
    "            data_chunk['year'] = data_chunk['year'].astype(int)\n",
    "            if month_or_quarter == \"month\":\n",
    "                data_chunk[month_or_quarter] = np.floor((data_chunk['week_end'] % 10000)/100)\n",
    "                data_chunk[month_or_quarter] = data_chunk[month_or_quarter].astype(int)\n",
    "\n",
    "                if int(year) == min_year:\n",
    "                    data_chunk = data_chunk[data_chunk.month >= min_month]\n",
    "                elif int(year) == max_year:\n",
    "                    data_chunk = data_chunk[data_chunk.month <= max_month]\n",
    "            elif month_or_quarter == \"quarter\":\n",
    "                data_chunk[month_or_quarter] = np.ceil(np.floor((data_chunk['week_end'] % 10000)/100)/3)\n",
    "                data_chunk[month_or_quarter] = data_chunk[month_or_quarter].astype(int)\n",
    "                if int(year) == min_year:\n",
    "                    data_chunk = data_chunk[data_chunk.quarter >= min_quarter]\n",
    "                elif int(year) == max_year:\n",
    "                    data_chunk = data_chunk[data_chunk.quarter <= max_quarter]\n",
    "\n",
    "            data_chunk['dma_code'] = data_chunk['store_code_uc'].map(dma_map)\n",
    "            data_chunk['sales'] = data_chunk['price'] * data_chunk['units'] / data_chunk['prmult']\n",
    "            data_chunk['module'] = int(module)\n",
    "            data_chunk['upc_ver_uc'] = data_chunk['upc'].map(upc_ver_map)\n",
    "            area_time_upc = data_chunk.groupby(['year', month_or_quarter, 'upc', 'upc_ver_uc', 'dma_code'], as_index = False).aggregate(aggregation_function).reindex(columns = data_chunk.columns)\n",
    "            area_time_upc_list.append(area_time_upc)\n",
    "\n",
    "    area_time_upc = pd.concat(area_time_upc_list)\n",
    "    area_time_upc = area_time_upc.groupby(['year', month_or_quarter, 'upc', 'upc_ver_uc', 'dma_code'], as_index = False).aggregate(aggregation_function).reindex(columns = area_time_upc.columns)\n",
    "    area_time_upc = area_time_upc.join(product_map[add_from_map], on=['upc','upc_ver_uc'], how='left')\n",
    "    area_time_upc = clean_data(code, area_time_upc)\n",
    "    area_time_upc['conversion'] = area_time_upc['size1_units'].map(conversion_map['conversion'])\n",
    "    area_time_upc['volume'] = area_time_upc['units'] * area_time_upc['size1_amount'] * area_time_upc['multi'] * area_time_upc['conversion']\n",
    "    area_time_upc['prices'] = area_time_upc['sales'] / area_time_upc['volume']\n",
    "    \n",
    "    area_time_upc.drop(['week_end'], axis=1, inplace=True)\n",
    "\n",
    "    # Normalize the prices by the CPI.  Let January 2010 = 1.\n",
    "    area_time_upc = adjust_inflation(area_time_upc, ['prices', 'sales'], month_or_quarter)\n",
    "\n",
    "    # Get the market sizes here, by summing volume within dma-time and then taking 1.5 times max within-dma\n",
    "    short_area_time_upc = area_time_upc[['dma_code', 'year', month_or_quarter, 'volume', 'sales']]\n",
    "    market_sizes = short_area_time_upc.groupby(['dma_code', 'year', month_or_quarter]).sum()\n",
    "    market_sizes['market_size'] = market_size_scale * market_sizes['volume'].groupby('dma_code').transform('max')\n",
    "    market_sizes = market_sizes.rename(columns = {'sales': 'total_sales', 'volume' : 'total_volume'})\n",
    "\n",
    "    # Save the output if this is month\n",
    "    if month_or_quarter == 'month':\n",
    "        market_sizes.to_csv('../../../../All/m_' + code + '/intermediate/market_sizes.csv', sep = ',', encoding = 'utf-8')\n",
    "\n",
    "    # Shares = volume / market size.  Map market sizes back and get shares.\n",
    "    area_time_upc = area_time_upc.join(market_sizes.drop('total_volume', axis=1), on = ['dma_code', 'year', month_or_quarter])\n",
    "    area_time_upc['shares'] = area_time_upc['volume'] / area_time_upc['market_size']\n",
    "\n",
    "    return area_time_upc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "automotive-simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded store file of 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['store_code_uc', 'upc', 'units', 'prmult', 'price', 'feature',\n",
       "       'display', 'year', 'month', 'dma_code', 'sales', 'module', 'upc_ver_uc',\n",
       "       'brand_code_uc', 'brand_descr', 'multi', 'size1_units', 'size1_amount',\n",
       "       'conversion', 'volume', 'prices', 'total_sales', 'market_size',\n",
       "       'shares'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### objective of this is to get area_month_upc BECAUSE THIS HAS STORE UC CODES!\n",
    "\n",
    "#setup\n",
    "code = '2641303020_8'\n",
    "info_dict = parse_info(code)\n",
    "info_dict.keys()\n",
    "final_unit = info_dict['FinalUnits']\n",
    "\n",
    "groups, modules = aux.get_groups_and_modules(info_dict[\"MarketDefinition\"])\n",
    "# FIXUP for 1 year\n",
    "#years = aux.get_years(info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "years = 2012\n",
    "year = '2012'\n",
    "\n",
    "# make conversion map\n",
    "\n",
    "#merger_start_date = WHAT IS THIS? - date announced\n",
    "#merger_stop_date = WHAT IS THIS? - date completed\n",
    "\n",
    "conversion_map = get_conversion_map(code, info_dict[\"FinalUnits\"])\n",
    "    \n",
    "area_month_upc = aggregate_movement(code, years, groups, modules, \"month\", conversion_map, info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "\n",
    "area_month_upc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "starting-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded store file of 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded store file of 2012\n"
     ]
    }
   ],
   "source": [
    "# creating area_month_upc file\n",
    "area_month_upc = aggregate_movement(code, years, groups, modules, \"month\", conversion_map, info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "area_month_upc = area_month_upc[['store_code_uc', 'upc', 'year', 'month', 'sales', 'dma_code', 'volume']]\n",
    "\n",
    "# loading stores\n",
    "stores = load_store_table('2012')\n",
    "stores_dict = stores[['year','parent_code', 'retailer_code', 'channel_code', 'dma_code']].to_dict()\n",
    "\n",
    "# inserting store type\n",
    "area_month_upc.insert(1, \"channel_code\", area_month_upc[\"store_code_uc\"].map(stores_dict[\"channel_code\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "boxed-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#area_month_upc_clean = area_month_upc_clean['channel_code'].map(stores_dict['channel_code'])\n",
    "#area_month_upc_clean['channel_code']\n",
    "#area_month_upc.insert(1, \"channel_code\", 0)\n",
    "\n",
    "area_month_upc.to_csv('channel_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "after-museum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded store file of 2012\n"
     ]
    }
   ],
   "source": [
    "stores = load_store_table('2012')\n",
    "stores.to_csv('stores_check.csv')\n",
    "\n",
    "stores = stores.sort_values(by = ['store_code_uc'])\n",
    "\n",
    "stores_dict = stores[['year','parent_code', 'retailer_code', 'channel_code', 'dma_code']].to_dict()\n",
    "\n",
    "#stores.columns()\n",
    "#stores['store']\n",
    "\n",
    "#stores_dict['channel_code']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "quality-public",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>parent_code</th>\n",
       "      <th>retailer_code</th>\n",
       "      <th>channel_code</th>\n",
       "      <th>store_zip3</th>\n",
       "      <th>fips_state_code</th>\n",
       "      <th>fips_state_descr</th>\n",
       "      <th>fips_county_code</th>\n",
       "      <th>fips_county_descr</th>\n",
       "      <th>dma_code</th>\n",
       "      <th>dma_descr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_code_uc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2012</td>\n",
       "      <td>4901</td>\n",
       "      <td>4901</td>\n",
       "      <td>D</td>\n",
       "      <td>199.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>DE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KENT</td>\n",
       "      <td>504.0</td>\n",
       "      <td>PHILADELPHIA PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2012</td>\n",
       "      <td>5851</td>\n",
       "      <td>5851</td>\n",
       "      <td>M</td>\n",
       "      <td>501.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>IA</td>\n",
       "      <td>127.0</td>\n",
       "      <td>MARSHALL</td>\n",
       "      <td>679.0</td>\n",
       "      <td>DES MOINES-AMES IA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>2012</td>\n",
       "      <td>5851</td>\n",
       "      <td>5851</td>\n",
       "      <td>M</td>\n",
       "      <td>606.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>31.0</td>\n",
       "      <td>COOK</td>\n",
       "      <td>602.0</td>\n",
       "      <td>CHICAGO IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>2012</td>\n",
       "      <td>5851</td>\n",
       "      <td>5851</td>\n",
       "      <td>M</td>\n",
       "      <td>461.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>IN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>MARION</td>\n",
       "      <td>527.0</td>\n",
       "      <td>INDIANAPOLIS IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2012</td>\n",
       "      <td>4904</td>\n",
       "      <td>4904</td>\n",
       "      <td>D</td>\n",
       "      <td>786.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HAYS</td>\n",
       "      <td>635.0</td>\n",
       "      <td>AUSTIN TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387662</th>\n",
       "      <td>2012</td>\n",
       "      <td>5851</td>\n",
       "      <td>5851</td>\n",
       "      <td>M</td>\n",
       "      <td>393.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MS</td>\n",
       "      <td>75.0</td>\n",
       "      <td>LAUDERDALE</td>\n",
       "      <td>711.0</td>\n",
       "      <td>MERIDIAN MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387747</th>\n",
       "      <td>2012</td>\n",
       "      <td>5851</td>\n",
       "      <td>5851</td>\n",
       "      <td>M</td>\n",
       "      <td>785.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>215.0</td>\n",
       "      <td>HIDALGO</td>\n",
       "      <td>636.0</td>\n",
       "      <td>HARLINGEN-WESLACO-BROWNSVILLE-MCALLEN TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388006</th>\n",
       "      <td>2012</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>F</td>\n",
       "      <td>279.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>53.0</td>\n",
       "      <td>CURRITUCK</td>\n",
       "      <td>544.0</td>\n",
       "      <td>NORFOLK-PORTSMOUTH-NEWPORT NEWS VA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388364</th>\n",
       "      <td>2012</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>F</td>\n",
       "      <td>274.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NC</td>\n",
       "      <td>81.0</td>\n",
       "      <td>GUILFORD</td>\n",
       "      <td>518.0</td>\n",
       "      <td>GREENSBORO-HIGH POINT-WINSTON SALEM NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388468</th>\n",
       "      <td>2012</td>\n",
       "      <td>5851</td>\n",
       "      <td>5851</td>\n",
       "      <td>M</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>9.0</td>\n",
       "      <td>ESSEX</td>\n",
       "      <td>506.0</td>\n",
       "      <td>BOSTON (MANCHESTER) MA-NH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36001 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               year  parent_code  retailer_code channel_code  store_zip3  \\\n",
       "store_code_uc                                                              \n",
       "273            2012         4901           4901            D       199.0   \n",
       "666            2012         5851           5851            M       501.0   \n",
       "884            2012         5851           5851            M       606.0   \n",
       "1069           2012         5851           5851            M       461.0   \n",
       "1086           2012         4904           4904            D       786.0   \n",
       "...             ...          ...            ...          ...         ...   \n",
       "8387662        2012         5851           5851            M       393.0   \n",
       "8387747        2012         5851           5851            M       785.0   \n",
       "8388006        2012           79             79            F       279.0   \n",
       "8388364        2012          111            111            F       274.0   \n",
       "8388468        2012         5851           5851            M        18.0   \n",
       "\n",
       "               fips_state_code fips_state_descr  fips_county_code  \\\n",
       "store_code_uc                                                       \n",
       "273                       10.0               DE               1.0   \n",
       "666                       19.0               IA             127.0   \n",
       "884                       17.0               IL              31.0   \n",
       "1069                      18.0               IN              97.0   \n",
       "1086                      48.0               TX             209.0   \n",
       "...                        ...              ...               ...   \n",
       "8387662                   28.0               MS              75.0   \n",
       "8387747                   48.0               TX             215.0   \n",
       "8388006                   37.0               NC              53.0   \n",
       "8388364                   37.0               NC              81.0   \n",
       "8388468                   25.0               MA               9.0   \n",
       "\n",
       "              fips_county_descr  dma_code  \\\n",
       "store_code_uc                               \n",
       "273                        KENT     504.0   \n",
       "666                    MARSHALL     679.0   \n",
       "884                        COOK     602.0   \n",
       "1069                     MARION     527.0   \n",
       "1086                       HAYS     635.0   \n",
       "...                         ...       ...   \n",
       "8387662              LAUDERDALE     711.0   \n",
       "8387747                 HIDALGO     636.0   \n",
       "8388006               CURRITUCK     544.0   \n",
       "8388364                GUILFORD     518.0   \n",
       "8388468                   ESSEX     506.0   \n",
       "\n",
       "                                              dma_descr  \n",
       "store_code_uc                                            \n",
       "273                                     PHILADELPHIA PA  \n",
       "666                                  DES MOINES-AMES IA  \n",
       "884                                          CHICAGO IL  \n",
       "1069                                    INDIANAPOLIS IN  \n",
       "1086                                          AUSTIN TX  \n",
       "...                                                 ...  \n",
       "8387662                                     MERIDIAN MS  \n",
       "8387747        HARLINGEN-WESLACO-BROWNSVILLE-MCALLEN TX  \n",
       "8388006              NORFOLK-PORTSMOUTH-NEWPORT NEWS VA  \n",
       "8388364          GREENSBORO-HIGH POINT-WINSTON SALEM NC  \n",
       "8388468                       BOSTON (MANCHESTER) MA-NH  \n",
       "\n",
       "[36001 rows x 11 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores\n",
    "#area_month_upc_clean.sort_values(by = ['store_code_uc'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
