{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bacterial-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import time\n",
    "import pyblp\n",
    "import auxiliary as aux\n",
    "import sqldf\n",
    "import pysqldf as ps\n",
    "from pandasql import sqldf\n",
    "import pandasql\n",
    "import os\n",
    "import re\n",
    "import itertools\n",
    "import shutil\n",
    "\n",
    "def parse_info(code):\n",
    "    file = open('../../../../All/m_' + code + '/info.txt', mode = 'r')\n",
    "    info_file = file.read()\n",
    "    file.close()\n",
    "\n",
    "    all_info_elements = re.finditer('\\[(.*?):(.*?)\\]', info_file, re.DOTALL)\n",
    "    info_dict = {}\n",
    "    for info in all_info_elements:\n",
    "        info_name = info.group(1).strip()\n",
    "        info_content = info.group(2).strip()\n",
    "        info_dict[info_name] = info_content\n",
    "    return info_dict\n",
    "\n",
    "def get_date_range(initial_year_string, final_year_string, pre_months = 24, post_months = 24):\n",
    "        initial_dt = datetime.strptime(initial_year_string, '%Y-%m-%d')\n",
    "        final_dt = datetime.strptime(final_year_string, '%Y-%m-%d')\n",
    "        initial_month_int = initial_dt.year * 12 + initial_dt.month\n",
    "        final_month_int = final_dt.year * 12 + final_dt.month\n",
    "        min_year, min_month = int_to_month(initial_month_int - pre_months)\n",
    "        max_year, max_month = int_to_month(final_month_int + post_months)\n",
    "\n",
    "        string_init = str(int(min_year)) + \"-\" + str(int(min_month))\n",
    "        string_final = str(int(max_year)) + \"-\" + str(int(max_month))\n",
    "        years_range = pd.date_range(string_init, string_final, freq='MS').strftime(\"%Y\").tolist()\n",
    "        months_range = pd.date_range(string_init, string_final, freq='MS').strftime(\"%m\").tolist()\n",
    "\n",
    "        date_range = pd.DataFrame(zip(years_range, months_range))\n",
    "\n",
    "        return date_range\n",
    "    \n",
    "def load_store_table(year):\n",
    "    store_path = \"../../../../Data/nielsen_extracts/RMS/\" + year + \"/Annual_Files/stores_\" + year + \".tsv\"\n",
    "    store_table = pd.read_csv(store_path, delimiter = \"\\t\", index_col = \"store_code_uc\")\n",
    "    print(\"Loaded store file of \"+ year)\n",
    "    return store_table\n",
    "\n",
    "def get_conversion_map(code, final_unit, method = 'mode'):\n",
    "    # Get in the conversion map -- size1_units, multiplication\n",
    "    master_conversion = pd.read_csv('../../../../All/master/unit_conversion.csv')\n",
    "    assert master_conversion['final_unit'].str.contains(final_unit).any(), \"Cannot find %r as a final_unit\" % final_unit\n",
    "    master_conversion = master_conversion[master_conversion['final_unit'] == final_unit]\n",
    "\n",
    "    these_units = pd.read_csv('../../../../All/m_' + code + '/properties/units_edited.csv')\n",
    "    these_units['conversion'] = 0\n",
    "\n",
    "    # Anything that has convert = 1 must be in the master folder\n",
    "    convertible = these_units.loc[these_units.convert == 1].copy()\n",
    "    for this_unit in convertible.units.unique():\n",
    "        assert master_conversion['initial_unit'].str.contains(this_unit).any(), \"Cannot find %r as an initial_unit\" % this_unit\n",
    "        if this_unit in master_conversion.initial_unit.unique():\n",
    "            convert_factor = master_conversion.conversion[master_conversion.initial_unit == this_unit].values\n",
    "            these_units.loc[these_units.units == this_unit, 'conversion'] = convert_factor\n",
    "            convertible.loc[convertible.units == this_unit, 'conversion'] = convert_factor\n",
    "\n",
    "    # Convert the total quantity\n",
    "    convertible['total_quantity'] = convertible['total_quantity'] * convertible['conversion']\n",
    "\n",
    "    # The \"method\" for convert = 0 is mapped to the \"method\" for the convert = 1\n",
    "    # with the largest quantity\n",
    "    where_largest = convertible.total_quantity.idxmax()\n",
    "    if method == 'mode':\n",
    "        base_size = convertible.loc[where_largest]['mode']\n",
    "        other_size = these_units[these_units.convert == 0]['mode']\n",
    "    else:\n",
    "        base_size = convertible.loc[where_largest]['median']\n",
    "        other_size = these_units[these_units.convert == 0]['median']\n",
    "\n",
    "    these_units.conversion[these_units.convert == 0] = convertible.conversion[where_largest] * base_size / other_size\n",
    "    these_units = these_units[['units', 'conversion']]\n",
    "    these_units = these_units.rename(columns = {'units' : 'size1_units'})\n",
    "    these_units = these_units.set_index('size1_units')\n",
    "\n",
    "    conversion_map = these_units.to_dict()\n",
    "    return conversion_map\n",
    "\n",
    "def aggregate_movement(code, years, groups, modules, month_or_quarter, conversion_map, merger_start_date, merger_stop_date, market_size_scale = 1.5, pre_months = 24, post_months = 24):\n",
    "\n",
    "    # Get the relevant range\n",
    "    stop_dt = datetime.strptime(merger_stop_date, '%Y-%m-%d')\n",
    "    start_dt = datetime.strptime(merger_start_date, '%Y-%m-%d')\n",
    "    stop_month_int = stop_dt.year * 12 + stop_dt.month\n",
    "    start_month_int = start_dt.year * 12 + start_dt.month\n",
    "\n",
    "    min_year, min_month = aux.int_to_month(start_month_int - pre_months)\n",
    "    max_year, max_month = aux.int_to_month(stop_month_int + post_months)\n",
    "    min_quarter = np.ceil(min_month/3)\n",
    "    max_quarter = np.ceil(max_month/3)\n",
    "\n",
    "    #manual fix for baby strained food\n",
    "    if ((code=='1817013020_3') & (max_year > 2008)):\n",
    "        max_year = 2008\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2008, years))\n",
    "\n",
    "    #manual fix for bread\n",
    "    if ((code=='2203820020_1') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for buns\n",
    "    if ((code=='2203820020_2') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for rolls\n",
    "    if ((code=='2203820020_3') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for pies\n",
    "    if ((code=='2203820020_8') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for bakery remaining\n",
    "    if ((code=='2203820020_10') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for cheesecake\n",
    "    if ((code=='2203820020_11') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "    #manual fix for biscuits\n",
    "    if ((code=='2203820020_12') & (max_year > 2012)):\n",
    "        max_year = 2012\n",
    "        max_month = 12\n",
    "        max_quarter = 4\n",
    "        years = list(filter(lambda x: int(x) <= 2012, years))\n",
    "\n",
    "        #manual fix for RBC_Bread\n",
    "    if ((code=='2033113020_2') & (min_year < 2007)):\n",
    "        min_year = 2007\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2007, years))\n",
    "\n",
    "        #manual fix for RBC_Cake\n",
    "    if ((code=='2033113020_3') & (min_year < 2007)):\n",
    "        min_year = 2007\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2007, years))\n",
    "\n",
    "        #manual fix for Headache pills\n",
    "    if ((code=='2373087020_1') & (min_year < 2010)):\n",
    "        min_year = 2010\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2010, years))\n",
    "\n",
    "        #manual fix for School and Office Supplies\n",
    "    if ((code=='2363232020_4') & (min_year < 2010)):\n",
    "        min_year = 2010\n",
    "        min_month = 1\n",
    "        min_quarter = 1\n",
    "        years = list(filter(lambda x: int(x) >= 2010, years))\n",
    "\n",
    "    area_time_upc_list = []\n",
    "    product_map = aux.get_product_map(list(set(groups)))\n",
    "    add_from_map = ['brand_code_uc', 'brand_descr', 'multi', 'size1_units', 'size1_amount']\n",
    "    aggregation_function = {'week_end' : 'first', 'units' : 'sum', 'prmult' : 'mean', 'price' : 'mean', 'feature' : 'first', 'display' : 'first', 'store_code_uc' : 'first', 'sales' : 'sum', 'module' : 'first'}\n",
    "\n",
    "    for year in years:\n",
    "        store_table = load_store_table(year)\n",
    "        store_map = store_table.to_dict()\n",
    "        dma_map = store_map['dma_code']\n",
    "        upc_ver_map = aux.get_upc_ver_uc_map(year)\n",
    "\n",
    "        for group, module in zip(groups, modules):\n",
    "            movement_table = aux.load_chunked_year_module_movement_table(year, group, module)\n",
    "\n",
    "            for data_chunk in tqdm(movement_table):\n",
    "                data_chunk['year'] = np.floor(data_chunk['week_end']/10000)\n",
    "                data_chunk['year'] = data_chunk['year'].astype(int)\n",
    "                if month_or_quarter == \"month\":\n",
    "                    data_chunk[month_or_quarter] = np.floor((data_chunk['week_end'] % 10000)/100)\n",
    "                    data_chunk[month_or_quarter] = data_chunk[month_or_quarter].astype(int)\n",
    "\n",
    "                    if int(year) == min_year:\n",
    "                        data_chunk = data_chunk[data_chunk.month >= min_month]\n",
    "                    elif int(year) == max_year:\n",
    "                        data_chunk = data_chunk[data_chunk.month <= max_month]\n",
    "                elif month_or_quarter == \"quarter\":\n",
    "                    data_chunk[month_or_quarter] = np.ceil(np.floor((data_chunk['week_end'] % 10000)/100)/3)\n",
    "                    data_chunk[month_or_quarter] = data_chunk[month_or_quarter].astype(int)\n",
    "                    if int(year) == min_year:\n",
    "                        data_chunk = data_chunk[data_chunk.quarter >= min_quarter]\n",
    "                    elif int(year) == max_year:\n",
    "                        data_chunk = data_chunk[data_chunk.quarter <= max_quarter]\n",
    "\n",
    "                data_chunk['dma_code'] = data_chunk['store_code_uc'].map(dma_map)\n",
    "                data_chunk['sales'] = data_chunk['price'] * data_chunk['units'] / data_chunk['prmult']\n",
    "                data_chunk['module'] = int(module)\n",
    "                data_chunk['upc_ver_uc'] = data_chunk['upc'].map(upc_ver_map)\n",
    "                area_time_upc = data_chunk.groupby(['year', month_or_quarter, 'upc', 'upc_ver_uc', 'dma_code'], as_index = False).aggregate(aggregation_function).reindex(columns = data_chunk.columns)\n",
    "                area_time_upc_list.append(area_time_upc)\n",
    "\n",
    "    area_time_upc = pd.concat(area_time_upc_list)\n",
    "    area_time_upc = area_time_upc.groupby(['year', month_or_quarter, 'upc', 'upc_ver_uc', 'dma_code'], as_index = False).aggregate(aggregation_function).reindex(columns = area_time_upc.columns)\n",
    "    area_time_upc = area_time_upc.join(product_map[add_from_map], on=['upc','upc_ver_uc'], how='left')\n",
    "    area_time_upc = clean_data(code, area_time_upc)\n",
    "    area_time_upc['conversion'] = area_time_upc['size1_units'].map(conversion_map['conversion'])\n",
    "    area_time_upc['volume'] = area_time_upc['units'] * area_time_upc['size1_amount'] * area_time_upc['multi'] * area_time_upc['conversion']\n",
    "    area_time_upc['prices'] = area_time_upc['sales'] / area_time_upc['volume']\n",
    "    \n",
    "    #area_time_upc.drop(['week_end','store_code_uc'], axis=1, inplace=True)\n",
    "\n",
    "    # Normalize the prices by the CPI.  Let January 2010 = 1.\n",
    "    area_time_upc = aux.adjust_inflation(area_time_upc, ['prices', 'sales'], month_or_quarter)\n",
    "\n",
    "    # Get the market sizes here, by summing volume within dma-time and then taking 1.5 times max within-dma\n",
    "    short_area_time_upc = area_time_upc[['dma_code', 'year', month_or_quarter, 'volume', 'sales']]\n",
    "    market_sizes = short_area_time_upc.groupby(['dma_code', 'year', month_or_quarter]).sum()\n",
    "    market_sizes['market_size'] = market_size_scale * market_sizes['volume'].groupby('dma_code').transform('max')\n",
    "    market_sizes = market_sizes.rename(columns = {'sales': 'total_sales', 'volume' : 'total_volume'})\n",
    "\n",
    "    # Save the output if this is month\n",
    "    if month_or_quarter == 'month':\n",
    "        market_sizes.to_csv('../../../../All/m_' + code + '/intermediate/market_sizes.csv', sep = ',', encoding = 'utf-8')\n",
    "\n",
    "    # Shares = volume / market size.  Map market sizes back and get shares.\n",
    "    area_time_upc = area_time_upc.join(market_sizes.drop('total_volume', axis=1), on = ['dma_code', 'year', month_or_quarter])\n",
    "    area_time_upc['shares'] = area_time_upc['volume'] / area_time_upc['market_size']\n",
    "\n",
    "    return area_time_upc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "purple-hanging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             conversion\n",
      "size1_units            \n",
      "OZ             0.028349\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-1ab578d87e29>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  these_units.conversion[these_units.convert == 0] = convertible.conversion[where_largest] * base_size / other_size\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../Data/nielsen_extracts/RMS/Master_Files/Latest/products.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-621adb57b08f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mconversion_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_conversion_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"FinalUnits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0marea_month_upc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_movement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"month\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversion_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DateAnnounced\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DateCompleted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#merger_start_date = WHAT IS THIS?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-1ab578d87e29>\u001b[0m in \u001b[0;36maggregate_movement\u001b[0;34m(code, years, groups, modules, month_or_quarter, conversion_map, merger_start_date, merger_stop_date, market_size_scale, pre_months, post_months)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0marea_time_upc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mproduct_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_product_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0madd_from_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'brand_code_uc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'brand_descr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'multi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size1_units'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size1_amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0maggregation_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'week_end'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'units'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prmult'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'price'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'feature'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'display'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'store_code_uc'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'first'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sales'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'module'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'first'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ECs/MarinaMurphy/Mergers/Codes/Mergers/Main/MarinaMurphy/auxiliary.py\u001b[0m in \u001b[0;36mget_product_map\u001b[0;34m(groups)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_product_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mproducts_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../../Data/nielsen_extracts/RMS/Master_Files/Latest/products.tsv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mproducts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproducts_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cp1252\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"upc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"upc_ver_uc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mint_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mwanted_products\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproducts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproducts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_group_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../Data/nielsen_extracts/RMS/Master_Files/Latest/products.tsv'"
     ]
    }
   ],
   "source": [
    "#setup\n",
    "code = '2641303020_8'\n",
    "info_dict = parse_info(code)\n",
    "info_dict.keys()\n",
    "final_unit = info_dict['FinalUnits']\n",
    "\n",
    "groups, modules = aux.get_groups_and_modules(info_dict[\"MarketDefinition\"])\n",
    "years = aux.get_years(info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "\n",
    "# make conversion map\n",
    "conversion_map = get_conversion_map(code, info_dict[\"FinalUnits\"])\n",
    "    \n",
    "area_month_upc = aggregate_movement(code, years, groups, modules, \"month\", conversion_map, info_dict[\"DateAnnounced\"], info_dict[\"DateCompleted\"])\n",
    "\n",
    "#merger_start_date = WHAT IS THIS?\n",
    "#merger_stop_date = WHAT IS THIS?\n",
    "\n",
    "# area_time_upc\n",
    "#aggregate_movement(code, years, groups, modules, 'month', conversion_map, merger_start_date, merger_stop_date, market_size_scale = 1.5, pre_months = 24, post_months = 24)\n",
    "\n",
    "\n",
    "#these_units.conversion[these_units.convert == 0] = convertible.conversion[where_largest] * base_size / other_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-hunter",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
