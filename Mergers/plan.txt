Data Structure
--------------
There should be a "price_data" folder.  The price_data folder should include

(1) README with a list of names of subfolders, what merger they correspond to (maybe a csv file)

(2) one subfolder for each merger considered.  

Each subfolder should contain

(1) a README with human-readable information about the merger, how products were formulated, etc.

(2) a make_data file that extracts and cleans data from the raw Nielsen database

(3) the data file (csv) generated by (2), in the format of the Nevo dataset

(4) a configuration file -- also generated by (2) -- that can be read in that includes dates of mergers, what we consider the pre- and post- period, which firms merged (in a way that can be mapped back to the IDs in the dataset).  This configuration file should include data that we could read in the post-analysis too (NAICS codes, etc.)


Code Structure
--------------
Create a script / set of functions that 

(1) reads in the dataset and is able to subset it properly to just use the pre-period in estimation

(2) run a variety of specifications on the data

    (a) run plot time series of predicted and actual price in the pre-period

    (b) run cross-validation to pick a specification

    (c) report diagnostics such as F-stats for instruments

(3) predict prices after simulating the merger


This whole process will take a while.  We will go into details of implementation as the work progresses, since that will require a lot of iteration to make decisions along the way.  But, a good place to start is to get the details down for one example (Miller and Weinberg (2017 ECMA)) and then use it as a template moving forward.